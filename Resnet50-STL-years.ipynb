{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler,Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "#from aspp import DeepLabHead\n",
    "#from create_dataset import NYUv2\n",
    "from LibMTL import Trainer\n",
    "#from LibMTL.model import resnet_dilated\n",
    "from LibMTL.model.resnet import resnet50\n",
    "from LibMTL.utils import set_random_seed, set_device\n",
    "from LibMTL.config import LibMTL_args, prepare_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LibMTL.loss import CELoss,  FocalLoss\n",
    "from LibMTL.metrics import F1Metric, AccMetric\n",
    "from LibMTL._record import _PerformanceMeter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--csv_file', default='/home3/jqwx33/SculptureMTL/sculpture-multi-class-remove-unknown.csv', type=str, help='path to the csv file')\n",
    "    parser.add_argument('--img_dir', default='/home3/jqwx33/SculptureMTL/selected_images', type=str, help='directory of images')\n",
    "    parser.add_argument('--train_bs', default=10,type=int, help='batch size for training')\n",
    "    parser.add_argument('--test_bs', default=10, type=int, help='batch size for testing')\n",
    "    parser.add_argument('--epochs', default=30,type=int, help='training epochs')\n",
    "    parser.add_argument('--weighting', default='DWA', type=str, help='weighting strategy')\n",
    "    parser.add_argument('--arch', default='MTAN', type=str, help='MTL architecture')\n",
    "    parser.add_argument('--gpu_id', default='0', type=str, help='gpu id')\n",
    "    parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
    "    parser.add_argument('--scheduler', default='step', type=str, help='learning rate scheduler type')\n",
    "    parser.add_argument('--optim', default='adamw', type=str, help='optimizer type')\n",
    "    \n",
    "    parser.add_argument('--mode', default='test', type=str, help='mode: train or test')\n",
    "    parser.add_argument('--save_path', default='/home3/jqwx33/SculptureMTL/result-year', type=str, help='save path')\n",
    "    parser.add_argument('--load_path', default='/home3/jqwx33/SculptureMTL/result-year/best.pt', type=str, help='load path for testing')\n",
    "    parser.add_argument('--T', default=2, type=int, help='DWA parameter T')\n",
    "    parser.add_argument('--step_size', default=50, type=int, help='scheduler step size')\n",
    "    parser.add_argument('--gamma', default=0.5, type=float, help='scheduler gamma')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='learning rate')\n",
    "    parser.add_argument('--weight_decay', default=0.0005, type=float, help='weight decay')\n",
    "    parser.add_argument('--rep_grad', action='store_true', default=False, help='compute representative gradients')\n",
    "    parser.add_argument('--multi_input', action='store_true', default=False, help='multi-input')\n",
    "    if sys.argv and sys.argv[0].endswith('ipykernel_launcher.py'):\n",
    "        args = parser.parse_args(args=[])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset  Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SculptureDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = self.data['image_path'].tolist()\n",
    "  \n",
    "\n",
    "        self.time_period_col = 'years_encoded'\n",
    "        \n",
    "         # Remove any rows with NaN values\n",
    "        #self.data = self.data.dropna(subset=[self.materials_col, self.genres_col, self.time_period_col])\n",
    "\n",
    "        #self.data[self.materials_col] = self.data[self.materials_col].apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.int64)\n",
    "        #self.data[self.genres_col] = self.data[self.genres_col].apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.int64)\n",
    "        self.data[self.time_period_col] = pd.to_numeric(self.data[self.time_period_col], errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        #materials = self.data.iloc[idx][self.materials_col].astype(np.int64)\n",
    "        #genres = self.data.iloc[idx][self.genres_col].astype(np.int64)\n",
    "        time_period = self.data.iloc[idx][self.time_period_col].astype(np.int64)\n",
    "\n",
    "        return image, {\n",
    "                       'time_period': torch.tensor(time_period, dtype=torch.long)}\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# Reshape layer for decoder\n",
    "class ReshapeLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "General Configuration:\n",
      "\tMode: train\n",
      "\tWighting: DWA\n",
      "\tArchitecture: MTAN\n",
      "\tRep_Grad: False\n",
      "\tMulti_Input: False\n",
      "\tSeed: 0\n",
      "\tSave Path: /home3/jqwx33/SculptureMTL/result-year\n",
      "\tLoad Path: None\n",
      "\tDevice: cuda:0\n",
      "DWA Configuration:\n",
      "\tT: 2\n",
      "Optimizer Configuration:\n",
      "\toptim: adamw\n",
      "\tlr: 0.001\n",
      "\tweight_decay: 0.0005\n",
      "Scheduler Configuration:\n",
      "\tscheduler: step\n",
      "\tstep_size: 50\n",
      "\tgamma: 0.5\n",
      "Encoder output shape: torch.Size([1, 2048, 8, 8])\n",
      "========================================\n",
      "Total Params: 102731405\n",
      "Trainable Params: 102731405\n",
      "Non-trainable Params: 0\n",
      "========================================\n",
      "LOG FORMAT | time_period_LOSS acc | TIME\n",
      "Epoch: 0000 | TRAIN: 2.8113 0.2121 | Time: 61.0271 | TEST: 2.0311 0.2246 | Time: 3.3907\n",
      "Save Model 0 to /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "Epoch: 0001 | TRAIN: 2.0809 0.2234 | Time: 60.3425 | TEST: 2.0710 0.2120 | Time: 3.3088\n",
      "Epoch: 0002 | TRAIN: 2.0084 0.2448 | Time: 60.4515 | TEST: 1.9734 0.2572 | Time: 3.3182\n",
      "Save Model 2 to /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "Epoch: 0003 | TRAIN: 1.9607 0.2537 | Time: 60.5525 | TEST: 1.9350 0.2790 | Time: 3.2846\n",
      "Save Model 3 to /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "Epoch: 0004 | TRAIN: 1.9240 0.2630 | Time: 60.5930 | TEST: 1.9717 0.2572 | Time: 3.2820\n",
      "Epoch: 0005 | TRAIN: 1.9037 0.2618 | Time: 60.5361 | TEST: 2.0557 0.2609 | Time: 3.3085\n",
      "Epoch: 0006 | TRAIN: 1.9144 0.2727 | Time: 60.5682 | TEST: 1.9758 0.2591 | Time: 3.3082\n",
      "Epoch: 0007 | TRAIN: 1.9453 0.2642 | Time: 60.5636 | TEST: 2.1002 0.2409 | Time: 3.2864\n",
      "Epoch: 0008 | TRAIN: 2.0588 0.2424 | Time: 60.4874 | TEST: 2.1825 0.2355 | Time: 3.3042\n",
      "Epoch: 0009 | TRAIN: 1.9451 0.2723 | Time: 60.5633 | TEST: 1.9545 0.2736 | Time: 3.2871\n",
      "Epoch: 0010 | TRAIN: 1.9285 0.2634 | Time: 60.5258 | TEST: 1.9587 0.2391 | Time: 3.2789\n",
      "Epoch: 0011 | TRAIN: 1.8864 0.2739 | Time: 60.5390 | TEST: 1.9107 0.2681 | Time: 3.3032\n",
      "Epoch: 0012 | TRAIN: 1.9059 0.2716 | Time: 60.5731 | TEST: 1.9718 0.2627 | Time: 3.2862\n",
      "Epoch: 0013 | TRAIN: 1.8811 0.2805 | Time: 60.4880 | TEST: 1.9352 0.2808 | Time: 3.3025\n",
      "Save Model 13 to /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "Epoch: 0014 | TRAIN: 1.8537 0.2988 | Time: 60.5496 | TEST: 1.9037 0.2917 | Time: 3.3160\n",
      "Save Model 14 to /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "Epoch: 0015 | TRAIN: 1.8785 0.2708 | Time: 60.5962 | TEST: 1.9378 0.2935 | Time: 3.3275\n",
      "Save Model 15 to /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "Epoch: 0016 | TRAIN: 2.0028 0.2541 | Time: 60.5164 | TEST: 2.0516 0.2464 | Time: 3.2805\n",
      "Epoch: 0017 | TRAIN: 1.9497 0.2747 | Time: 60.5514 | TEST: 2.0237 0.2699 | Time: 3.2977\n",
      "Epoch: 0018 | TRAIN: 1.8960 0.2723 | Time: 60.5315 | TEST: 1.9138 0.2681 | Time: 3.2838\n",
      "Epoch: 0019 | TRAIN: 1.8786 0.2840 | Time: 60.5088 | TEST: 1.9451 0.2754 | Time: 3.3043\n",
      "Epoch: 0020 | TRAIN: 1.8721 0.2910 | Time: 60.5630 | TEST: 3.0062 0.2464 | Time: 3.2901\n",
      "Epoch: 0021 | TRAIN: 1.8804 0.2743 | Time: 60.5032 | TEST: 1.9121 0.2989 | Time: 3.3104\n",
      "Save Model 21 to /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "Epoch: 0022 | TRAIN: 1.8439 0.2941 | Time: 60.5838 | TEST: 1.9181 0.2880 | Time: 3.2808\n",
      "Epoch: 0023 | TRAIN: 1.8418 0.2836 | Time: 60.5972 | TEST: 1.9097 0.2862 | Time: 3.3032\n",
      "Epoch: 0024 | TRAIN: 1.8861 0.2906 | Time: 60.5983 | TEST: 2.0583 0.2518 | Time: 3.3141\n",
      "Epoch: 0025 | TRAIN: 1.8957 0.2789 | Time: 60.5909 | TEST: 2.1665 0.2627 | Time: 3.2827\n",
      "Epoch: 0026 | TRAIN: 1.8699 0.2953 | Time: 60.5826 | TEST: 1.9810 0.2536 | Time: 3.3090\n",
      "Epoch: 0027 | TRAIN: 1.8548 0.2910 | Time: 60.5159 | TEST: 1.9432 0.2808 | Time: 3.3057\n",
      "Epoch: 0028 | TRAIN: 1.8387 0.2964 | Time: 60.4784 | TEST: 1.9313 0.2736 | Time: 3.2842\n",
      "Epoch: 0029 | TRAIN: 1.8242 0.2984 | Time: 60.5752 | TEST: 1.9243 0.2736 | Time: 3.2900\n",
      "========================================\n",
      "Best Result: Epoch 21, result {'time_period': [0.29891304347826086]}\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "# Main function to set up and run the model\n",
    "def main(params):\n",
    "    \n",
    "    if not os.path.exists(params.save_path):\n",
    "        os.makedirs(params.save_path)\n",
    "        \n",
    "\n",
    "    # Prepare arguments for optimizer and scheduler\n",
    "    kwargs, optim_param, scheduler_param = prepare_args(params)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.RandomRotation(30),      # Randomly rotate the image by 30 degrees\n",
    "        #transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "\n",
    "    ])\n",
    "\n",
    "    dataset = SculptureDataset(csv_file=params.csv_file, img_dir=params.img_dir, transform=transform)\n",
    "\n",
    "\n",
    "    train_idx, temp_idx = train_test_split(range(len(dataset)), test_size=0.3, random_state=params.seed)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=params.seed) \n",
    "\n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    val_set = Subset(dataset, val_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=params.train_bs, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    " \n",
    "    # Define tasks and metrics\n",
    "    task_dict = {\n",
    "\n",
    "        'time_period': {\n",
    "            'metrics': ['acc'],\n",
    "            'metrics_fn': AccMetric(),\n",
    "            'loss_fn': CELoss(),\n",
    "            'weight': [1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Function to return the encoder class\n",
    "    def encoder_class():\n",
    "        return resnet50(pretrained=True)\n",
    "\n",
    "    class SculptureEncoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SculptureEncoder, self).__init__()\n",
    "            self.encoder = resnet50(pretrained=True)  \n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.encoder(x)\n",
    "            print(\"Encoder output shape:\", x.shape)\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize encoder to get the output shape\n",
    "    \n",
    "    encoder = SculptureEncoder()\n",
    "    dummy_input = torch.randn(1, 3, 256, 256)\n",
    "    encoder_output = encoder(dummy_input)\n",
    "    flattened_size = encoder_output.view(1, -1).size(1)\n",
    "    \n",
    "    num_out_channels = {\n",
    "\n",
    "    'time_period': len(np.unique(dataset.data[dataset.time_period_col]))\n",
    "}\n",
    "\n",
    "    \n",
    "    #Decoder class for each task\n",
    "    \n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(Decoder, self).__init__()\n",
    "            self.decoder = nn.Sequential(\n",
    "                ReshapeLayer(),\n",
    "                nn.Linear(input_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(512, output_dim),\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.decoder(x)\n",
    "    \n",
    "        \n",
    "\n",
    "    decoders = nn.ModuleDict({task: Decoder(flattened_size, num_out_channels[task]) for task in task_dict.keys()})\n",
    "    \n",
    "    \n",
    "    # Trainer class for the sculpture model\n",
    "\n",
    "    class SculptureTrainer(Trainer):\n",
    "        def __init__(self, task_dict, weighting, architecture, encoder_class, decoders, rep_grad, multi_input, optim_param, scheduler_param, **kwargs):\n",
    "            super(SculptureTrainer, self).__init__(task_dict=task_dict, weighting=weighting, architecture=architecture, encoder_class=encoder_class, decoders=decoders, rep_grad=rep_grad, multi_input=multi_input, optim_param=optim_param, scheduler_param=scheduler_param, **kwargs)\n",
    "            \n",
    "\n",
    "        def process_preds(self, preds):\n",
    "            return preds\n",
    "\n",
    "        def _process_data(self, loader):\n",
    "            try:\n",
    "                data, label = next(loader[1])\n",
    "            except:\n",
    "                loader[1] = iter(loader[0])\n",
    "                data, label = next(loader[1])\n",
    "            inputs = data.to(self.device, non_blocking=True)\n",
    "            labels = {task: label[task].to(self.device, non_blocking=True) for task in self.task_name}\n",
    "            return inputs, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    SculptureModel = SculptureTrainer(task_dict=task_dict, weighting=params.weighting, architecture=params.arch, encoder_class=encoder_class, decoders=decoders,\n",
    "                                      rep_grad=params.rep_grad, multi_input=params.multi_input, optim_param=optim_param, scheduler_param=scheduler_param,\n",
    "                                      save_path=params.save_path, load_path=params.load_path, **kwargs)\n",
    "\n",
    "    if params.mode == 'train':\n",
    "        try:\n",
    "            SculptureModel.train(train_loader, val_loader, params.epochs)\n",
    "\n",
    "\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    elif params.mode == 'test':\n",
    "        try:\n",
    "            SculptureModel.test(test_loader)\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose between 'train' and 'test'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    params = parse_args()\n",
    "    set_device(params.gpu_id)\n",
    "    set_random_seed(params.seed)\n",
    "    main(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "General Configuration:\n",
      "\tMode: test\n",
      "\tWighting: DWA\n",
      "\tArchitecture: MTAN\n",
      "\tRep_Grad: False\n",
      "\tMulti_Input: False\n",
      "\tSeed: 0\n",
      "\tSave Path: /home3/jqwx33/SculptureMTL/result-year\n",
      "\tLoad Path: /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "\tDevice: cuda:0\n",
      "DWA Configuration:\n",
      "\tT: 2\n",
      "Optimizer Configuration:\n",
      "\toptim: adamw\n",
      "\tlr: 0.001\n",
      "\tweight_decay: 0.0005\n",
      "Scheduler Configuration:\n",
      "\tscheduler: step\n",
      "\tstep_size: 50\n",
      "\tgamma: 0.5\n",
      "Encoder output shape: torch.Size([1, 2048, 8, 8])\n",
      "Load Model from - /home3/jqwx33/SculptureMTL/result-year/best.pt\n",
      "========================================\n",
      "Total Params: 102731405\n",
      "Trainable Params: 102731405\n",
      "Non-trainable Params: 0\n",
      "========================================\n",
      "LOG FORMAT | time_period_LOSS acc | TIME\n",
      "TEST: 1.9026 0.2536 | Time: 3.7832\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "# Main function to set up and run the model\n",
    "def main(params):\n",
    "    \n",
    "    if not os.path.exists(params.save_path):\n",
    "        os.makedirs(params.save_path)\n",
    "        \n",
    "\n",
    "    # Prepare arguments for optimizer and scheduler\n",
    "    kwargs, optim_param, scheduler_param = prepare_args(params)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.RandomRotation(30),      # Randomly rotate the image by 30 degrees\n",
    "        #transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "\n",
    "    ])\n",
    "\n",
    "    dataset = SculptureDataset(csv_file=params.csv_file, img_dir=params.img_dir, transform=transform)\n",
    "\n",
    "    \n",
    "    train_idx, temp_idx = train_test_split(range(len(dataset)), test_size=0.3, random_state=params.seed)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=params.seed)  # 在剩余的20%中再划分为验证集和测试集\n",
    "\n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    val_set = Subset(dataset, val_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=params.train_bs, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "    # Define tasks and metrics\n",
    "    # Define tasks and metrics\n",
    "    task_dict = {\n",
    "\n",
    "        'time_period': {\n",
    "            'metrics': ['acc'],\n",
    "            'metrics_fn': AccMetric(),\n",
    "            'loss_fn': CELoss(),\n",
    "            'weight': [1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Function to return the encoder class\n",
    "    def encoder_class():\n",
    "        return resnet50(pretrained=True)\n",
    "\n",
    "    class SculptureEncoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SculptureEncoder, self).__init__()\n",
    "            self.encoder = resnet50(pretrained=True) \n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.encoder(x)\n",
    "            print(\"Encoder output shape:\", x.shape)\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize encoder to get the output shape\n",
    "    \n",
    "    encoder = SculptureEncoder()\n",
    "    dummy_input = torch.randn(1, 3, 256, 256)\n",
    "    encoder_output = encoder(dummy_input)\n",
    "    flattened_size = encoder_output.view(1, -1).size(1)\n",
    "    \n",
    "    num_out_channels = {\n",
    "\n",
    "    'time_period': len(np.unique(dataset.data[dataset.time_period_col]))\n",
    "}\n",
    "\n",
    "    \n",
    "    #Decoder class for each task\n",
    "    \n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(Decoder, self).__init__()\n",
    "            self.decoder = nn.Sequential(\n",
    "                ReshapeLayer(),\n",
    "                nn.Linear(input_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(512, output_dim),\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.decoder(x)\n",
    "    \n",
    "        \n",
    "\n",
    "    decoders = nn.ModuleDict({task: Decoder(flattened_size, num_out_channels[task]) for task in task_dict.keys()})\n",
    "    \n",
    "    \n",
    "    # Trainer class for the sculpture model\n",
    "\n",
    "    class SculptureTrainer(Trainer):\n",
    "        def __init__(self, task_dict, weighting, architecture, encoder_class, decoders, rep_grad, multi_input, optim_param, scheduler_param, **kwargs):\n",
    "            super(SculptureTrainer, self).__init__(task_dict=task_dict, weighting=weighting, architecture=architecture, encoder_class=encoder_class, decoders=decoders, rep_grad=rep_grad, multi_input=multi_input, optim_param=optim_param, scheduler_param=scheduler_param, **kwargs)\n",
    "            \n",
    "\n",
    "        def process_preds(self, preds):\n",
    "            return preds\n",
    "\n",
    "        def _process_data(self, loader):\n",
    "            try:\n",
    "                data, label = next(loader[1])\n",
    "            except:\n",
    "                loader[1] = iter(loader[0])\n",
    "                data, label = next(loader[1])\n",
    "            inputs = data.to(self.device, non_blocking=True)\n",
    "            labels = {task: label[task].to(self.device, non_blocking=True) for task in self.task_name}\n",
    "            return inputs, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    SculptureModel = SculptureTrainer(task_dict=task_dict, weighting=params.weighting, architecture=params.arch, encoder_class=encoder_class, decoders=decoders,\n",
    "                                      rep_grad=params.rep_grad, multi_input=params.multi_input, optim_param=optim_param, scheduler_param=scheduler_param,\n",
    "                                      save_path=params.save_path, load_path=params.load_path, **kwargs)\n",
    "\n",
    "    if params.mode == 'train':\n",
    "        try:\n",
    "            SculptureModel.train(train_loader, val_loader, params.epochs)\n",
    "\n",
    "\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    elif params.mode == 'test':\n",
    "        try:\n",
    "            SculptureModel.test(test_loader)\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose between 'train' and 'test'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    params = parse_args()\n",
    "    set_device(params.gpu_id)\n",
    "    set_random_seed(params.seed)\n",
    "    main(params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
