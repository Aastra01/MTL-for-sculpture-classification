{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler,Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "#from aspp import DeepLabHead\n",
    "#from create_dataset import NYUv2\n",
    "from LibMTL import Trainer\n",
    "#from LibMTL.model import resnet_dilated\n",
    "from LibMTL.model.resnet import resnet50\n",
    "from LibMTL.utils import set_random_seed, set_device\n",
    "from LibMTL.config import LibMTL_args, prepare_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LibMTL.loss import CELoss,  FocalLoss\n",
    "from LibMTL.metrics import F1Metric, AccMetric\n",
    "from LibMTL._record import _PerformanceMeter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--csv_file', default='/home3/jqwx33/SculptureMTL/sculpture-multi-class-remove-unknown.csv', type=str, help='path to the csv file')\n",
    "    parser.add_argument('--img_dir', default='/home3/jqwx33/SculptureMTL/selected_images', type=str, help='directory of images')\n",
    "    parser.add_argument('--train_bs', default=10,type=int, help='batch size for training')\n",
    "    parser.add_argument('--test_bs', default=10, type=int, help='batch size for testing')\n",
    "    parser.add_argument('--epochs', default=30,type=int, help='training epochs')\n",
    "    parser.add_argument('--weighting', default='DWA', type=str, help='weighting strategy')\n",
    "    parser.add_argument('--arch', default='MTAN', type=str, help='MTL architecture')\n",
    "    parser.add_argument('--gpu_id', default='0', type=str, help='gpu id')\n",
    "    parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
    "    parser.add_argument('--scheduler', default='step', type=str, help='learning rate scheduler type')\n",
    "    parser.add_argument('--optim', default='adamw', type=str, help='optimizer type')\n",
    "    \n",
    "    parser.add_argument('--mode', default='test', type=str, help='mode: train or test')\n",
    "    parser.add_argument('--save_path', default='/home3/jqwx33/SculptureMTL/result-ge2', type=str, help='save path')\n",
    "    parser.add_argument('--load_path', default='/home3/jqwx33/SculptureMTL/result-ge2/best.pt', type=str, help='load path for testing')\n",
    "    parser.add_argument('--T', default=2, type=int, help='DWA parameter T')\n",
    "    parser.add_argument('--step_size', default=50, type=int, help='scheduler step size')\n",
    "    parser.add_argument('--gamma', default=0.5, type=float, help='scheduler gamma')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='learning rate')\n",
    "    parser.add_argument('--weight_decay', default=0.0005, type=float, help='weight decay')\n",
    "    parser.add_argument('--rep_grad', action='store_true', default=False, help='compute representative gradients')\n",
    "    parser.add_argument('--multi_input', action='store_true', default=False, help='multi-input')\n",
    "    if sys.argv and sys.argv[0].endswith('ipykernel_launcher.py'):\n",
    "        args = parser.parse_args(args=[])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset  Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SculptureDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = self.data['image_path'].tolist()\n",
    "  \n",
    "       # self.materials_col = 'materials_encoded'\n",
    "        self.genres_col = 'genres_encoded'\n",
    "        #self.time_period_col = 'years_encoded'\n",
    "        \n",
    "         # Remove any rows with NaN values\n",
    "        #self.data = self.data.dropna(subset=[self.materials_col, self.genres_col, self.time_period_col])\n",
    "\n",
    "        #self.data[self.materials_col] = self.data[self.materials_col].apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.int64)\n",
    "        self.data[self.genres_col] = self.data[self.genres_col].apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.int64)\n",
    "        #self.data[self.time_period_col] = pd.to_numeric(self.data[self.time_period_col], errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        #materials = self.data.iloc[idx][self.materials_col].astype(np.int64)\n",
    "        genres = self.data.iloc[idx][self.genres_col].astype(np.int64)\n",
    "        #time_period = self.data.iloc[idx][self.time_period_col].astype(np.int64)\n",
    "\n",
    "        return image, {\n",
    "                       'genres': torch.tensor(genres, dtype=torch.long)\n",
    "                       }\n",
    "\n",
    "\n",
    "        \n",
    "# Reshape layer for decoder\n",
    "class ReshapeLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "General Configuration:\n",
      "\tMode: train\n",
      "\tWighting: DWA\n",
      "\tArchitecture: MTAN\n",
      "\tRep_Grad: False\n",
      "\tMulti_Input: False\n",
      "\tSeed: 0\n",
      "\tSave Path: /home3/jqwx33/SculptureMTL/result-ge2\n",
      "\tLoad Path: None\n",
      "\tDevice: cuda:0\n",
      "DWA Configuration:\n",
      "\tT: 2\n",
      "Optimizer Configuration:\n",
      "\toptim: adamw\n",
      "\tlr: 0.001\n",
      "\tweight_decay: 0.0005\n",
      "Scheduler Configuration:\n",
      "\tscheduler: step\n",
      "\tstep_size: 50\n",
      "\tgamma: 0.5\n",
      "Encoder output shape: torch.Size([1, 2048, 8, 8])\n",
      "========================================\n",
      "Total Params: 102730379\n",
      "Trainable Params: 102730379\n",
      "Non-trainable Params: 0\n",
      "========================================\n",
      "LOG FORMAT | genres_LOSS acc | TIME\n",
      "Epoch: 0000 | TRAIN: 2.2150 0.5789 | Time: 60.9595 | TEST: 2.3330 0.5254 | Time: 3.4212\n",
      "Save Model 0 to /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "Epoch: 0001 | TRAIN: 1.4313 0.6142 | Time: 60.3184 | TEST: 1.4603 0.6123 | Time: 3.2817\n",
      "Save Model 1 to /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "Epoch: 0002 | TRAIN: 1.3962 0.6224 | Time: 60.4669 | TEST: 1.3657 0.6304 | Time: 3.2802\n",
      "Save Model 2 to /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "Epoch: 0003 | TRAIN: 1.3747 0.6344 | Time: 60.5135 | TEST: 1.3410 0.6413 | Time: 3.3134\n",
      "Save Model 3 to /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "Epoch: 0004 | TRAIN: 1.3170 0.6321 | Time: 60.5276 | TEST: 1.3267 0.6322 | Time: 3.3097\n",
      "Epoch: 0005 | TRAIN: 1.3010 0.6375 | Time: 60.4858 | TEST: 1.3134 0.6286 | Time: 3.2986\n",
      "Epoch: 0006 | TRAIN: 1.2823 0.6422 | Time: 60.5053 | TEST: 1.3312 0.6486 | Time: 3.2826\n",
      "Save Model 6 to /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "Epoch: 0007 | TRAIN: 1.4451 0.6150 | Time: 60.5087 | TEST: 5.4967 0.5290 | Time: 3.3075\n",
      "Epoch: 0008 | TRAIN: 1.4885 0.6018 | Time: 60.5399 | TEST: 1.3891 0.6159 | Time: 3.3085\n",
      "Epoch: 0009 | TRAIN: 1.3334 0.6313 | Time: 60.5360 | TEST: 1.3844 0.6341 | Time: 3.2865\n",
      "Epoch: 0010 | TRAIN: 1.3175 0.6336 | Time: 60.4913 | TEST: 1.4241 0.6141 | Time: 3.9836\n",
      "Epoch: 0011 | TRAIN: 1.3138 0.6356 | Time: 60.4951 | TEST: 1.3584 0.6232 | Time: 3.6391\n",
      "Epoch: 0012 | TRAIN: 1.3481 0.6321 | Time: 60.5199 | TEST: 1.3807 0.6268 | Time: 3.3096\n",
      "Epoch: 0013 | TRAIN: 1.3166 0.6387 | Time: 60.4986 | TEST: 1.3691 0.6322 | Time: 3.2884\n",
      "Epoch: 0014 | TRAIN: 1.2965 0.6457 | Time: 60.5622 | TEST: 1.3350 0.6322 | Time: 3.3083\n",
      "Epoch: 0015 | TRAIN: 1.2850 0.6395 | Time: 60.5898 | TEST: 1.3143 0.6486 | Time: 3.3164\n",
      "Epoch: 0016 | TRAIN: 1.2710 0.6453 | Time: 60.5615 | TEST: 1.3898 0.6341 | Time: 3.2807\n",
      "Epoch: 0017 | TRAIN: 1.2676 0.6484 | Time: 60.5333 | TEST: 1.4849 0.6341 | Time: 3.3139\n",
      "Epoch: 0018 | TRAIN: 1.2734 0.6461 | Time: 60.5861 | TEST: 1.3442 0.6341 | Time: 3.3083\n",
      "Epoch: 0019 | TRAIN: 1.2679 0.6554 | Time: 60.5169 | TEST: 1.3508 0.6467 | Time: 3.2869\n",
      "Epoch: 0020 | TRAIN: 1.2767 0.6410 | Time: 60.5147 | TEST: 1.2815 0.6359 | Time: 3.2871\n",
      "Epoch: 0021 | TRAIN: 1.2423 0.6453 | Time: 60.5160 | TEST: 1.3076 0.6341 | Time: 3.3067\n",
      "Epoch: 0022 | TRAIN: 1.2314 0.6519 | Time: 60.6192 | TEST: 1.4156 0.6268 | Time: 3.2797\n",
      "Epoch: 0023 | TRAIN: 1.2397 0.6616 | Time: 60.5691 | TEST: 1.3723 0.6413 | Time: 3.2825\n",
      "Epoch: 0024 | TRAIN: 1.2415 0.6453 | Time: 60.5815 | TEST: 1.3261 0.6486 | Time: 3.2861\n",
      "Epoch: 0025 | TRAIN: 1.2578 0.6469 | Time: 60.5294 | TEST: 1.3574 0.6431 | Time: 3.3131\n",
      "Epoch: 0026 | TRAIN: 1.2542 0.6503 | Time: 60.6076 | TEST: 1.3434 0.6522 | Time: 3.2893\n",
      "Save Model 26 to /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "Epoch: 0027 | TRAIN: 1.2185 0.6570 | Time: 60.5436 | TEST: 1.5956 0.6286 | Time: 3.3072\n",
      "Epoch: 0028 | TRAIN: 1.2379 0.6488 | Time: 60.5018 | TEST: 1.3133 0.6286 | Time: 3.3010\n",
      "Epoch: 0029 | TRAIN: 1.1912 0.6605 | Time: 60.5639 | TEST: 1.2717 0.6431 | Time: 3.2884\n",
      "========================================\n",
      "Best Result: Epoch 26, result {'genres': [0.6521739130434783]}\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "#train 0.6\n",
    "\n",
    "# Main function to set up and run the model\n",
    "def main(params):\n",
    "    \n",
    "    if not os.path.exists(params.save_path):\n",
    "        os.makedirs(params.save_path)\n",
    "        \n",
    "\n",
    "    # Prepare arguments for optimizer and scheduler\n",
    "    kwargs, optim_param, scheduler_param = prepare_args(params)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.RandomRotation(30),      # Randomly rotate the image by 30 degrees\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "\n",
    "    dataset = SculptureDataset(csv_file=params.csv_file, img_dir=params.img_dir, transform=transform)\n",
    "\n",
    "    train_idx, temp_idx = train_test_split(range(len(dataset)), test_size=0.3, random_state=params.seed)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=params.seed)  \n",
    "\n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    val_set = Subset(dataset, val_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=params.train_bs, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "    # Define tasks and metrics\n",
    "    # Define tasks and metrics\n",
    "    task_dict = {\n",
    "\n",
    "        'genres': {\n",
    "            'metrics': ['acc'],\n",
    "            'metrics_fn': AccMetric(),\n",
    "            'loss_fn':CELoss(),\n",
    "            'weight': [1]\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    # Function to return the encoder class\n",
    "    def encoder_class():\n",
    "        return resnet50(pretrained=True)\n",
    "\n",
    "    class SculptureEncoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SculptureEncoder, self).__init__()\n",
    "            self.encoder = resnet50(pretrained=True)  \n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.encoder(x)\n",
    "            print(\"Encoder output shape:\", x.shape)\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize encoder to get the output shape\n",
    "    \n",
    "    encoder = SculptureEncoder()\n",
    "    dummy_input = torch.randn(1, 3, 256, 256)\n",
    "    encoder_output = encoder(dummy_input)\n",
    "    flattened_size = encoder_output.view(1, -1).size(1)\n",
    "    \n",
    "    num_out_channels = {\n",
    "    'genres': len(np.unique(dataset.data[dataset.genres_col]))\n",
    "   \n",
    "}\n",
    "\n",
    "    \n",
    "    #Decoder class for each task\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(Decoder, self).__init__()\n",
    "            self.decoder = nn.Sequential(\n",
    "                ReshapeLayer(),\n",
    "                nn.Linear(input_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.6),\n",
    "                nn.Linear(512, output_dim),\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.decoder(x)\n",
    "        \n",
    "   \n",
    "    \n",
    "\n",
    "    decoders = nn.ModuleDict({task: Decoder(flattened_size, num_out_channels[task]) for task in task_dict.keys()})\n",
    "    \n",
    "    \n",
    "    # Trainer class for the sculpture model\n",
    "\n",
    "    class SculptureTrainer(Trainer):\n",
    "        def __init__(self, task_dict, weighting, architecture, encoder_class, decoders, rep_grad, multi_input, optim_param, scheduler_param, **kwargs):\n",
    "            super(SculptureTrainer, self).__init__(task_dict=task_dict, weighting=weighting, architecture=architecture, encoder_class=encoder_class, decoders=decoders, rep_grad=rep_grad, multi_input=multi_input, optim_param=optim_param, scheduler_param=scheduler_param, **kwargs)\n",
    "            \n",
    "\n",
    "        def process_preds(self, preds):\n",
    "            return preds\n",
    "\n",
    "        def _process_data(self, loader):\n",
    "            try:\n",
    "                data, label = next(loader[1])\n",
    "            except:\n",
    "                loader[1] = iter(loader[0])\n",
    "                data, label = next(loader[1])\n",
    "            inputs = data.to(self.device, non_blocking=True)\n",
    "            labels = {task: label[task].to(self.device, non_blocking=True) for task in self.task_name}\n",
    "            return inputs, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    SculptureModel = SculptureTrainer(task_dict=task_dict, weighting=params.weighting, architecture=params.arch, encoder_class=encoder_class, decoders=decoders,\n",
    "                                      rep_grad=params.rep_grad, multi_input=params.multi_input, optim_param=optim_param, scheduler_param=scheduler_param,\n",
    "                                      save_path=params.save_path, load_path=params.load_path, **kwargs)\n",
    "\n",
    "    if params.mode == 'train':\n",
    "        try:\n",
    "            SculptureModel.train(train_loader, val_loader, params.epochs)\n",
    "\n",
    "\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    elif params.mode == 'test':\n",
    "        try:\n",
    "            SculptureModel.test(test_loader)\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose between 'train' and 'test'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    params = parse_args()\n",
    "    set_device(params.gpu_id)\n",
    "    set_random_seed(params.seed)\n",
    "    main(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "General Configuration:\n",
      "\tMode: test\n",
      "\tWighting: DWA\n",
      "\tArchitecture: MTAN\n",
      "\tRep_Grad: False\n",
      "\tMulti_Input: False\n",
      "\tSeed: 0\n",
      "\tSave Path: /home3/jqwx33/SculptureMTL/result-ge2\n",
      "\tLoad Path: /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "\tDevice: cuda:0\n",
      "DWA Configuration:\n",
      "\tT: 2\n",
      "Optimizer Configuration:\n",
      "\toptim: adamw\n",
      "\tlr: 0.001\n",
      "\tweight_decay: 0.0005\n",
      "Scheduler Configuration:\n",
      "\tscheduler: step\n",
      "\tstep_size: 50\n",
      "\tgamma: 0.5\n",
      "Encoder output shape: torch.Size([1, 2048, 8, 8])\n",
      "Load Model from - /home3/jqwx33/SculptureMTL/result-ge2/best.pt\n",
      "========================================\n",
      "Total Params: 102730379\n",
      "Trainable Params: 102730379\n",
      "Non-trainable Params: 0\n",
      "========================================\n",
      "LOG FORMAT | genres_LOSS acc | TIME\n",
      "TEST: 1.3463 0.6413 | Time: 3.3711\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "# Main function to set up and run the model\n",
    "def main(params):\n",
    "    \n",
    "    if not os.path.exists(params.save_path):\n",
    "        os.makedirs(params.save_path)\n",
    "        \n",
    "\n",
    "    # Prepare arguments for optimizer and scheduler\n",
    "    kwargs, optim_param, scheduler_param = prepare_args(params)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.RandomRotation(30),      # Randomly rotate the image by 30 degrees\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "\n",
    "    ])\n",
    "\n",
    "    dataset = SculptureDataset(csv_file=params.csv_file, img_dir=params.img_dir, transform=transform)\n",
    "\n",
    "    train_idx, temp_idx = train_test_split(range(len(dataset)), test_size=0.3, random_state=params.seed)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=params.seed)  \n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    val_set = Subset(dataset, val_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=params.train_bs, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=params.test_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "    # Define tasks and metrics\n",
    "    task_dict = {\n",
    "\n",
    "        'genres': {\n",
    "            'metrics': ['acc'],\n",
    "            'metrics_fn': AccMetric(),\n",
    "            'loss_fn':CELoss(),\n",
    "            'weight': [1]\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    # Function to return the encoder class\n",
    "    def encoder_class():\n",
    "        return resnet50(pretrained=True)\n",
    "\n",
    "    class SculptureEncoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SculptureEncoder, self).__init__()\n",
    "            self.encoder = resnet50(pretrained=True)  \n",
    "        def forward(self, x):\n",
    "            x = self.encoder(x)\n",
    "            print(\"Encoder output shape:\", x.shape)\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize encoder to get the output shape\n",
    "    \n",
    "    encoder = SculptureEncoder()\n",
    "    dummy_input = torch.randn(1, 3, 256, 256)\n",
    "    encoder_output = encoder(dummy_input)\n",
    "    flattened_size = encoder_output.view(1, -1).size(1)\n",
    "    \n",
    "    num_out_channels = {\n",
    "    'genres': len(np.unique(dataset.data[dataset.genres_col]))\n",
    "   \n",
    "}\n",
    "\n",
    "    \n",
    "    #Decoder class for each task\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(Decoder, self).__init__()\n",
    "            self.decoder = nn.Sequential(\n",
    "                ReshapeLayer(),\n",
    "                nn.Linear(input_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.6),\n",
    "                nn.Linear(512, output_dim),\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.decoder(x)\n",
    "        \n",
    "   \n",
    "\n",
    "    decoders = nn.ModuleDict({task: Decoder(flattened_size, num_out_channels[task]) for task in task_dict.keys()})\n",
    "    \n",
    "    \n",
    "    # Trainer class for the sculpture model\n",
    "\n",
    "    class SculptureTrainer(Trainer):\n",
    "        def __init__(self, task_dict, weighting, architecture, encoder_class, decoders, rep_grad, multi_input, optim_param, scheduler_param, **kwargs):\n",
    "            super(SculptureTrainer, self).__init__(task_dict=task_dict, weighting=weighting, architecture=architecture, encoder_class=encoder_class, decoders=decoders, rep_grad=rep_grad, multi_input=multi_input, optim_param=optim_param, scheduler_param=scheduler_param, **kwargs)\n",
    "            \n",
    "\n",
    "        def process_preds(self, preds):\n",
    "            return preds\n",
    "\n",
    "        def _process_data(self, loader):\n",
    "            try:\n",
    "                data, label = next(loader[1])\n",
    "            except:\n",
    "                loader[1] = iter(loader[0])\n",
    "                data, label = next(loader[1])\n",
    "            inputs = data.to(self.device, non_blocking=True)\n",
    "            labels = {task: label[task].to(self.device, non_blocking=True) for task in self.task_name}\n",
    "            return inputs, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    SculptureModel = SculptureTrainer(task_dict=task_dict, weighting=params.weighting, architecture=params.arch, encoder_class=encoder_class, decoders=decoders,\n",
    "                                      rep_grad=params.rep_grad, multi_input=params.multi_input, optim_param=optim_param, scheduler_param=scheduler_param,\n",
    "                                      save_path=params.save_path, load_path=params.load_path, **kwargs)\n",
    "\n",
    "    if params.mode == 'train':\n",
    "        try:\n",
    "            SculptureModel.train(train_loader, val_loader, params.epochs)\n",
    "\n",
    "\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    elif params.mode == 'test':\n",
    "        try:\n",
    "            SculptureModel.test(test_loader)\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose between 'train' and 'test'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    params = parse_args()\n",
    "    set_device(params.gpu_id)\n",
    "    set_random_seed(params.seed)\n",
    "    main(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
